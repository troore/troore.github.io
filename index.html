<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="troore&#39;s">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="troore&#39;s">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="troore&#39;s">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>troore's</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">troore's</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/07/arxiv-20170801-chang-snowball/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="troore">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="troore's">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/07/arxiv-20170801-chang-snowball/" itemprop="url">Compiling Deep Learning Models for Custom Hardware Accelerators</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-07T12:13:39+08:00">
                2017-08-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Summary</p>
<p>Snowflake: custom hardware accelerator with instruction set</p>
<p>The ISCAS’17 paper describing Snowflake is not available now. It seems like GPU.</p>
<p>NN related feature: COOP and INDP.</p>
<p>Snowball: compiler</p>
<p>Contributions</p>
<ol>
<li>compilation</li>
</ol>
<p>NN specific instructions: MAC instruction’s COOP and INDP modes.</p>
<p>Low level optimization techniques.</p>
<ol>
<li><p>map kernel sizes (where?)</p>
</li>
<li><p>load balancing</p>
</li>
</ol>
<p>Break the maps data into multiple load instructions and distribute evenly with the kernel loads.</p>
<p>Drawbacks</p>
<p>The authors do not explain how to make a decision on their second contribution.</p>
<p>Questions</p>
<ol>
<li>I believe it could work, but why on FPGA?</li>
<li>If I move a GPU architecture on FPGA, who will win?</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/07/arxiv-20170731-baskin-streaming-qnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="troore">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="troore's">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/07/arxiv-20170731-baskin-streaming-qnn/" itemprop="url">Streaming Architecture for Large-Scale Quantized Neural Networks on an FPGA-Based Dataflow Platform</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-07T09:06:36+08:00">
                2017-08-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Strength"><a href="#Strength" class="headerlink" title="Strength"></a>Strength</h1><p>Backbone: BNN and streaming.</p>
<p>Programming model support: Maxeler DFE manager.</p>
<h1 id="Weakness"><a href="#Weakness" class="headerlink" title="Weakness"></a>Weakness</h1><p>No contributions.</p>
<h1 id="Detailed-comments"><a href="#Detailed-comments" class="headerlink" title="Detailed comments"></a>Detailed comments</h1><p><strong>Questions</strong></p>
<ol>
<li><p>What techniques do they apply or invent for the streaming optimization?</p>
</li>
<li><p>How to decide task patitioning between different FPGAs?</p>
</li>
</ol>
<p><strong>Experiment</strong></p>
<ol>
<li><p>Performance is much lower than GPUs and other FPGA works.</p>
</li>
<li><p>No proof for scalability for multiple FPGAs.</p>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/18/micro-2016-shijinzhang-cambricon-x/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="troore">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="troore's">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/18/micro-2016-shijinzhang-cambricon-x/" itemprop="url">MICRO'16 Cambricon-X Review</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-18T16:05:26+08:00">
                2017-07-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Detailed-Comments"><a href="#Detailed-Comments" class="headerlink" title="Detailed Comments"></a>Detailed Comments</h1><h2 id="Background-and-Motivation"><a href="#Background-and-Motivation" class="headerlink" title="Background and Motivation"></a>Background and Motivation</h2><p>An intuitive optimization is to directly integrate sparsity encoding/decoding modules into existing DianNao or DaDianNao architecture, so as to reduce off-chip memory accesses as well. However, this solution may not be efficient for two main reasons: </p>
<ol>
<li><p>the number of total operations remain the same, because the pruned synapses are still filled with zero values, incurring significant waste of computational resource,</p>
</li>
<li><p>neither the centralized architecture (e.g., DianNao) nor the symmetric tiled architecture (e.g., DaDianNao) can adapt to irregularity of sparse NNs.</p>
</li>
</ol>
<h2 id="Accelerator-Design"><a href="#Accelerator-Design" class="headerlink" title="Accelerator Design"></a>Accelerator Design</h2><p>All the PEs are connected in a topology of Fat-tree in order to avoid wiring congestion.</p>
<p>As the number of synapses of different neurons may significantly differ from each other, we allow SBs in different PEs to load new data from the memory asynchronously to improve overall efficiency.</p>
<p><strong>IM:</strong> Instead of distributing an indexing module to each PE, we design a centralized indexing module in the BC and only transfer the indexed neurons to PEs, which can significantly reduce the bandwidth requirement between the neural buffer and PEs because the number of data after indexing is much smaller in sparse networks.</p>
<p><strong>Aside:</strong> Fortunately, systolic array doesn’t have this problem. We could deploy an IM in each PE, as the inter-PE connection could greatly reduce the bandwidth between PE and neuron buffers.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/15/fccm-2017-yijinguan-fpdnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="troore">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="troore's">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/15/fccm-2017-yijinguan-fpdnn/" itemprop="url">FCCM'17 FP-DNN Review</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-15T16:33:45+08:00">
                2017-07-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>Title</strong>: FP-DNN: An Automated Framework for Mapping Deep Neural Networks onto FPGAs with RTL-HLS Hybrid Templates</p>
<p><strong>Conference</strong>: FCCM 2017</p>
<p><strong>doi</strong>: <a href="http://ieeexplore.ieee.org/document/7966671/" target="_blank" rel="external">http://ieeexplore.ieee.org/document/7966671/</a></p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>FPGA-based accelerator is a promising solution for computation and communication intensive DNNs, considering its performance, flexibility and energy efficiency. Unfortunately, conventional accelerator design flows make it difficult for FPGA developers to keep up with the fast pace of innovations in DNNs. This paper proposes an automation framework to deploy DNNs described with software framework (TensorFlow) on FPGA. This framework is general enough to support various DNN models like CNN, LSTM, etc. It uses an optimized matrix multiplication unit to perform core computation for all models. It also applies communication optimization to improve off-chip memory access efficiency.</p>
<h1 id="Strength"><a href="#Strength" class="headerlink" title="Strength"></a>Strength</h1><p>TensorFlow is a persuasive software library for mapping numerical computation depicted by flow graph onto hardware platforms, especially for machine learning applications. This work provides TensorFlow with FPGA support at the first time.</p>
<p>Given an application expressed by dataflow graph, and FPGA platform with hardware resource constraints, the authors formulate the minimization of number of off-chip buffers allocated for intermediate results generated by a graph node as a graph coloring problem.</p>
<p>This work implements a matrix multiplication (<em>MM</em>) unit as a kernel computation unit for a variety of layers in different models, such as convolutional layers, LSTM layers, etc. Its performance outperforms Intel’s <em>MM</em> hardware library and MKL software library.</p>
<p>For communication optimization, the authors propose a method called <em>Column-major</em> to avoid duplicate DDR memory footprint as well as increase memory burst length to improve off-chip access bandwidth.</p>
<h1 id="Weakness"><a href="#Weakness" class="headerlink" title="Weakness"></a>Weakness</h1><p>The computation unit is implemented directly by RTL. It is not flexible and scalable for different requirement of DNN models, as well FPGA platform switching.</p>
<p>Although avoiding duplicate DDR memory footprint, the <em>Column-major</em> method still needs redundant BRAM resources.</p>
<h1 id="Detailed-Comments"><a href="#Detailed-Comments" class="headerlink" title="Detailed Comments"></a>Detailed Comments</h1><p><strong>Hardware Implementation</strong></p>
<p>There is hardware resource usage of <em>Data Arranger</em>, but there is no running time for it.</p>
<p><em>MM</em> unit is implemented as fixed computation unit by RTL. Considering the fact that this work aims to map dataflow graphs like Figure 2(b) onto FPGA, if there are multiple implementations for different nodes, we have to manually implement them one by one. Thus it is not flexible and scalable for multi-FPGA extension.</p>
<p>Another problem is, the authors state that the fixed <em>MM</em> could accelerate FC layers by batching. However, is batching is suggested for LSTM, given latency requirement?</p>
<p>As for the communiation optimization, the <em>Row-major</em> method is useless to be illutrated in this paper. I don’t think it is necessary to put it on purpose to illustrate the benefit of <em>Column-major</em> way.</p>
<p><strong>Automation</strong></p>
<p>Why is the <em>Symbolic Compiler</em> is written in C++ and OpenCL? We do not see any details on how to translate TensorFlow programming model to instantiate the hardware templates either.</p>
<p><strong>Experiment</strong></p>
<p>Only CNN performance is provided and compared with previous works. How to demonstrate its generalarity for other models, in terms of high performance?</p>
<p>What is authors’ contribution to <em>MM</em> performance optimization?</p>
<p>The most important motivation of the RTL implementation for <em>MM</em> unit is that current designs cannot explore as much fine-grained optimization as in RTL designs. However, there is no illutration on what “fine-grained” optimization cannot be explored by current HLS tools. And there is no performance comparison with state-of-the-art HLS implementation of <em>MM</em>. As far as I know, the systolic array implementation of <em>MM</em> in [Jie, et al., FPGA’15] could achieve more than 300 GFlops, which is comparative with the results in Table I in this paper.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="troore" />
          <p class="site-author-name" itemprop="name">troore</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">troore</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
